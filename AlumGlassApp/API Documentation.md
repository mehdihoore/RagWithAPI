# AlumGlass API

## Overview

The AlumGlass API provides a unified interface for querying various services including search engines, Wikipedia, and custom models from OpenAI. This API allows users to perform hybrid searches and obtain relevant responses using a specified model.

## Base URL

The base URL for the API is:

```
http://localhost:8000
```

## Endpoints

### POST /query

This endpoint processes a query, performs searches across multiple services, and returns a response using the specified OpenAI model.

#### Request

**URL**: `/query`

**Method**: `POST`

**Content-Type**: `application/json`

**Request Body**:

```json
{
    "query": "What is the capital of France?",
    "collection_name": "mabahes",
    "prompt": null,
    "print_results": true,
    "model": "gpt-4.0-turbo"
}
```

**Fields**:

- `query` (string): The query to be processed.
- `collection_name` (string, optional): The name of the collection to search in. Defaults to `"mabahes"`.
- `prompt` (string, optional): Custom prompt for the OpenAI model. Defaults to `null`.
- `print_results` (boolean, optional): If `true`, prints search results to the console. Defaults to `true`.
- `model` (string, optional): The OpenAI model to be used for generating the response. Defaults to `"gpt-4.0-turbo"`.

#### Response

**Content-Type**: `application/json`

**Response Body**:

```json
{
    "answer": "The capital of France is Paris.",
    "mabhas_references": ["Reference 1", "Reference 2"],
    "confidence": "High",
    "additional_sources": ["Google", "Wikipedia"]
}
```

**Fields**:

- `answer` (string): The main response generated by the OpenAI model.
- `mabhas_references` (array of strings): References from the hybrid search service.
- `confidence` (string): Confidence level of the generated answer.
- `additional_sources` (array of strings): Sources of additional information used.

## Python Example

Here is a Python example demonstrating how to interact with the API using the `requests` library:

```python
import requests
import json

BASE_URL = "http://localhost:8000"

def query_alumglass(query, collection_name="mabahes", prompt=None, print_results=True, model="gpt-4.0-turbo"):
    url = f"{BASE_URL}/query"
    headers = {
        "Content-Type": "application/json"
    }
    payload = {
        "query": query,
        "collection_name": collection_name,
        "prompt": prompt,
        "print_results": print_results,
        "model": model
    }
    response = requests.post(url, headers=headers, data=json.dumps(payload))
    return response.json()

# Example usage
response = query_alumglass("What is the capital of France?")
print(response)
```

## Error Handling

- **500 Internal Server Error**: Indicates an internal error in the server. The API will log the error details.

## Additional Information

- Ensure the server is running locally at `http://localhost:8000`.
- The API can be tested using tools like Postman or Curl, or through the provided Python example.

---

